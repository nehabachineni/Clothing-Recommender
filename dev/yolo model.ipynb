{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4174b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import urllib\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from utils.utils import plot_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22621c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/image', 'train/annos']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'000001.json': '000001.jpg',\n",
       " '000002.json': '000002.jpg',\n",
       " '000003.json': '000003.jpg',\n",
       " '000004.json': '000004.jpg',\n",
       " '000005.json': '000005.jpg',\n",
       " '000006.json': '000006.jpg',\n",
       " '000007.json': '000007.jpg',\n",
       " '000008.json': '000008.jpg',\n",
       " '000009.json': '000009.jpg',\n",
       " '000010.json': '000010.jpg',\n",
       " '000011.json': '000011.jpg',\n",
       " '000012.json': '000012.jpg',\n",
       " '000013.json': '000013.jpg',\n",
       " '000014.json': '000014.jpg',\n",
       " '000015.json': '000015.jpg',\n",
       " '000016.json': '000016.jpg',\n",
       " '000017.json': '000017.jpg',\n",
       " '000018.json': '000018.jpg',\n",
       " '000019.json': '000019.jpg',\n",
       " '000020.json': '000020.jpg',\n",
       " '000021.json': '000021.jpg',\n",
       " '000022.json': '000022.jpg',\n",
       " '000023.json': '000023.jpg',\n",
       " '000024.json': '000024.jpg',\n",
       " '000025.json': '000025.jpg',\n",
       " '000026.json': '000026.jpg',\n",
       " '000027.json': '000027.jpg',\n",
       " '000028.json': '000028.jpg',\n",
       " '000029.json': '000029.jpg',\n",
       " '000030.json': '000030.jpg',\n",
       " '000031.json': '000031.jpg',\n",
       " '000032.json': '000032.jpg',\n",
       " '000033.json': '000033.jpg',\n",
       " '000034.json': '000034.jpg',\n",
       " '000035.json': '000035.jpg',\n",
       " '000036.json': '000036.jpg',\n",
       " '000037.json': '000037.jpg',\n",
       " '000038.json': '000038.jpg',\n",
       " '000039.json': '000039.jpg',\n",
       " '000040.json': '000040.jpg',\n",
       " '000041.json': '000041.jpg',\n",
       " '000042.json': '000042.jpg',\n",
       " '000043.json': '000043.jpg',\n",
       " '000044.json': '000044.jpg',\n",
       " '000045.json': '000045.jpg',\n",
       " '000046.json': '000046.jpg',\n",
       " '000047.json': '000047.jpg',\n",
       " '000048.json': '000048.jpg',\n",
       " '000049.json': '000049.jpg',\n",
       " '000050.json': '000050.jpg',\n",
       " '000051.json': '000051.jpg',\n",
       " '000052.json': '000052.jpg',\n",
       " '000053.json': '000053.jpg',\n",
       " '000054.json': '000054.jpg',\n",
       " '000055.json': '000055.jpg',\n",
       " '000056.json': '000056.jpg',\n",
       " '000057.json': '000057.jpg',\n",
       " '000058.json': '000058.jpg',\n",
       " '000059.json': '000059.jpg',\n",
       " '000060.json': '000060.jpg',\n",
       " '000061.json': '000061.jpg',\n",
       " '000062.json': '000062.jpg',\n",
       " '000063.json': '000063.jpg',\n",
       " '000064.json': '000064.jpg',\n",
       " '000065.json': '000065.jpg',\n",
       " '000066.json': '000066.jpg',\n",
       " '000067.json': '000067.jpg',\n",
       " '000068.json': '000068.jpg',\n",
       " '000069.json': '000069.jpg',\n",
       " '000070.json': '000070.jpg',\n",
       " '000071.json': '000071.jpg',\n",
       " '000072.json': '000072.jpg',\n",
       " '000073.json': '000073.jpg',\n",
       " '000074.json': '000074.jpg',\n",
       " '000075.json': '000075.jpg',\n",
       " '000076.json': '000076.jpg',\n",
       " '000077.json': '000077.jpg',\n",
       " '000078.json': '000078.jpg',\n",
       " '000079.json': '000079.jpg',\n",
       " '000080.json': '000080.jpg',\n",
       " '000081.json': '000081.jpg',\n",
       " '000082.json': '000082.jpg',\n",
       " '000083.json': '000083.jpg',\n",
       " '000084.json': '000084.jpg',\n",
       " '000085.json': '000085.jpg',\n",
       " '000086.json': '000086.jpg',\n",
       " '000087.json': '000087.jpg',\n",
       " '000088.json': '000088.jpg',\n",
       " '000089.json': '000089.jpg',\n",
       " '000090.json': '000090.jpg',\n",
       " '000091.json': '000091.jpg',\n",
       " '000092.json': '000092.jpg',\n",
       " '000093.json': '000093.jpg',\n",
       " '000094.json': '000094.jpg',\n",
       " '000095.json': '000095.jpg',\n",
       " '000096.json': '000096.jpg',\n",
       " '000097.json': '000097.jpg',\n",
       " '000098.json': '000098.jpg',\n",
       " '000099.json': '000099.jpg',\n",
       " '000100.json': '000100.jpg',\n",
       " '000101.json': '000101.jpg',\n",
       " '000102.json': '000102.jpg',\n",
       " '000103.json': '000103.jpg',\n",
       " '000104.json': '000104.jpg',\n",
       " '000105.json': '000105.jpg',\n",
       " '000106.json': '000106.jpg',\n",
       " '000107.json': '000107.jpg',\n",
       " '000108.json': '000108.jpg',\n",
       " '000109.json': '000109.jpg',\n",
       " '000110.json': '000110.jpg',\n",
       " '000111.json': '000111.jpg',\n",
       " '000112.json': '000112.jpg',\n",
       " '000113.json': '000113.jpg',\n",
       " '000114.json': '000114.jpg',\n",
       " '000115.json': '000115.jpg',\n",
       " '000116.json': '000116.jpg',\n",
       " '000117.json': '000117.jpg',\n",
       " '000118.json': '000118.jpg',\n",
       " '000119.json': '000119.jpg',\n",
       " '000120.json': '000120.jpg',\n",
       " '000121.json': '000121.jpg',\n",
       " '000122.json': '000122.jpg',\n",
       " '000123.json': '000123.jpg',\n",
       " '000124.json': '000124.jpg',\n",
       " '000125.json': '000125.jpg',\n",
       " '000126.json': '000126.jpg',\n",
       " '000127.json': '000127.jpg',\n",
       " '000128.json': '000128.jpg',\n",
       " '000129.json': '000129.jpg',\n",
       " '000130.json': '000130.jpg',\n",
       " '000131.json': '000131.jpg',\n",
       " '000132.json': '000132.jpg',\n",
       " '000133.json': '000133.jpg',\n",
       " '000134.json': '000134.jpg',\n",
       " '000135.json': '000135.jpg',\n",
       " '000136.json': '000136.jpg',\n",
       " '000137.json': '000137.jpg',\n",
       " '000138.json': '000138.jpg',\n",
       " '000139.json': '000139.jpg',\n",
       " '000140.json': '000140.jpg',\n",
       " '000141.json': '000141.jpg',\n",
       " '000142.json': '000142.jpg',\n",
       " '000143.json': '000143.jpg',\n",
       " '000144.json': '000144.jpg',\n",
       " '000145.json': '000145.jpg',\n",
       " '000146.json': '000146.jpg',\n",
       " '000147.json': '000147.jpg',\n",
       " '000148.json': '000148.jpg',\n",
       " '000149.json': '000149.jpg',\n",
       " '000150.json': '000150.jpg',\n",
       " '000151.json': '000151.jpg',\n",
       " '000152.json': '000152.jpg',\n",
       " '000153.json': '000153.jpg',\n",
       " '000154.json': '000154.jpg',\n",
       " '000155.json': '000155.jpg',\n",
       " '000156.json': '000156.jpg',\n",
       " '000157.json': '000157.jpg',\n",
       " '000158.json': '000158.jpg',\n",
       " '000159.json': '000159.jpg',\n",
       " '000160.json': '000160.jpg',\n",
       " '000161.json': '000161.jpg',\n",
       " '000162.json': '000162.jpg',\n",
       " '000163.json': '000163.jpg',\n",
       " '000164.json': '000164.jpg',\n",
       " '000165.json': '000165.jpg',\n",
       " '000166.json': '000166.jpg',\n",
       " '000167.json': '000167.jpg',\n",
       " '000168.json': '000168.jpg',\n",
       " '000169.json': '000169.jpg',\n",
       " '000170.json': '000170.jpg',\n",
       " '000171.json': '000171.jpg',\n",
       " '000172.json': '000172.jpg',\n",
       " '000173.json': '000173.jpg',\n",
       " '000174.json': '000174.jpg',\n",
       " '000175.json': '000175.jpg',\n",
       " '000176.json': '000176.jpg',\n",
       " '000177.json': '000177.jpg',\n",
       " '000178.json': '000178.jpg',\n",
       " '000179.json': '000179.jpg',\n",
       " '000180.json': '000180.jpg',\n",
       " '000181.json': '000181.jpg',\n",
       " '000182.json': '000182.jpg',\n",
       " '000183.json': '000183.jpg',\n",
       " '000184.json': '000184.jpg',\n",
       " '000185.json': '000185.jpg',\n",
       " '000186.json': '000186.jpg',\n",
       " '000187.json': '000187.jpg',\n",
       " '000188.json': '000188.jpg',\n",
       " '000189.json': '000189.jpg',\n",
       " '000190.json': '000190.jpg',\n",
       " '000191.json': '000191.jpg',\n",
       " '000192.json': '000192.jpg',\n",
       " '000193.json': '000193.jpg',\n",
       " '000194.json': '000194.jpg',\n",
       " '000195.json': '000195.jpg',\n",
       " '000196.json': '000196.jpg',\n",
       " '000197.json': '000197.jpg',\n",
       " '000198.json': '000198.jpg',\n",
       " '000199.json': '000199.jpg',\n",
       " '000200.json': '000200.jpg'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "mypath = \"train/\"\n",
    "\n",
    "files_path=[join(mypath, k) for k in listdir(mypath)]\n",
    "print(files_path)\n",
    "anna_s=sorted(listdir(files_path[1]))[:200]\n",
    "img_s=sorted(listdir(files_path[0]))[:200]\n",
    "\n",
    "\n",
    "for ann_path, img_path in zip(anna_s,img_s):\n",
    "    data[ann_path]=img_path    \n",
    "        \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d802bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item2': {'segmentation': [[460,\n",
       "     438,\n",
       "     374,\n",
       "     484,\n",
       "     251,\n",
       "     520,\n",
       "     269,\n",
       "     586,\n",
       "     298,\n",
       "     622,\n",
       "     410,\n",
       "     623,\n",
       "     410,\n",
       "     567,\n",
       "     413,\n",
       "     591,\n",
       "     420,\n",
       "     623,\n",
       "     465,\n",
       "     622,\n",
       "     456,\n",
       "     561,\n",
       "     466,\n",
       "     504,\n",
       "     460,\n",
       "     438],\n",
       "    [374, 484, 251, 520, 269, 586, 298, 622, 410, 623, 410, 567, 374, 484],\n",
       "    [460,\n",
       "     438,\n",
       "     374,\n",
       "     484,\n",
       "     410,\n",
       "     567,\n",
       "     413,\n",
       "     591,\n",
       "     420,\n",
       "     623,\n",
       "     465,\n",
       "     622,\n",
       "     456,\n",
       "     561,\n",
       "     466,\n",
       "     504,\n",
       "     460,\n",
       "     438]],\n",
       "   'scale': 2,\n",
       "   'viewpoint': 2,\n",
       "   'zoom_in': 3,\n",
       "   'landmarks': [251,\n",
       "    520,\n",
       "    1,\n",
       "    374,\n",
       "    484,\n",
       "    1,\n",
       "    460,\n",
       "    438,\n",
       "    1,\n",
       "    269,\n",
       "    586,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    410,\n",
       "    567,\n",
       "    1,\n",
       "    413,\n",
       "    591,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    456,\n",
       "    561,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0],\n",
       "   'style': 0,\n",
       "   'bounding_box': [249, 423, 466, 623],\n",
       "   'category_id': 8,\n",
       "   'occlusion': 2,\n",
       "   'category_name': 'trousers'},\n",
       "  'source': 'user',\n",
       "  'pair_id': 1,\n",
       "  'item1': {'segmentation': [[257,\n",
       "     35,\n",
       "     261,\n",
       "     89,\n",
       "     228,\n",
       "     123,\n",
       "     137,\n",
       "     103,\n",
       "     45,\n",
       "     91,\n",
       "     1,\n",
       "     176,\n",
       "     0,\n",
       "     332,\n",
       "     47,\n",
       "     447,\n",
       "     151,\n",
       "     401,\n",
       "     141,\n",
       "     366,\n",
       "     129,\n",
       "     328,\n",
       "     141,\n",
       "     364,\n",
       "     219,\n",
       "     485,\n",
       "     274,\n",
       "     603,\n",
       "     401,\n",
       "     590,\n",
       "     467,\n",
       "     502,\n",
       "     442,\n",
       "     336,\n",
       "     369,\n",
       "     195,\n",
       "     348,\n",
       "     138,\n",
       "     363,\n",
       "     163,\n",
       "     372,\n",
       "     197,\n",
       "     433,\n",
       "     137,\n",
       "     396,\n",
       "     92,\n",
       "     341,\n",
       "     35,\n",
       "     257,\n",
       "     35],\n",
       "    [1, 176, 0, 332, 47, 447, 151, 401, 141, 366, 129, 328, 1, 176],\n",
       "    [348, 138, 363, 163, 372, 197, 433, 137, 396, 92, 341, 35, 348, 138]],\n",
       "   'scale': 3,\n",
       "   'viewpoint': 2,\n",
       "   'zoom_in': 2,\n",
       "   'landmarks': [182,\n",
       "    54,\n",
       "    1,\n",
       "    45,\n",
       "    91,\n",
       "    1,\n",
       "    137,\n",
       "    103,\n",
       "    1,\n",
       "    228,\n",
       "    123,\n",
       "    1,\n",
       "    261,\n",
       "    89,\n",
       "    1,\n",
       "    257,\n",
       "    35,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    47,\n",
       "    447,\n",
       "    2,\n",
       "    151,\n",
       "    401,\n",
       "    2,\n",
       "    141,\n",
       "    366,\n",
       "    2,\n",
       "    129,\n",
       "    328,\n",
       "    2,\n",
       "    141,\n",
       "    364,\n",
       "    2,\n",
       "    219,\n",
       "    485,\n",
       "    2,\n",
       "    274,\n",
       "    603,\n",
       "    2,\n",
       "    401,\n",
       "    590,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    442,\n",
       "    336,\n",
       "    2,\n",
       "    369,\n",
       "    195,\n",
       "    1,\n",
       "    348,\n",
       "    138,\n",
       "    1,\n",
       "    363,\n",
       "    163,\n",
       "    1,\n",
       "    372,\n",
       "    197,\n",
       "    1,\n",
       "    433,\n",
       "    137,\n",
       "    2,\n",
       "    396,\n",
       "    92,\n",
       "    2,\n",
       "    341,\n",
       "    35,\n",
       "    1],\n",
       "   'style': 1,\n",
       "   'bounding_box': [0, 29, 466, 622],\n",
       "   'category_id': 1,\n",
       "   'occlusion': 2,\n",
       "   'category_name': 'short sleeve top'}},\n",
       " 'train/image/000001.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing=[]\n",
    "for ann in data:\n",
    "#     print(type(ann))\n",
    "    ann_path = files_path[1]+\"/\"+ann\n",
    "    img_path = files_path[0]+\"/\"+data[ann]\n",
    "    k=json.load(open(ann_path))\n",
    "    clothing.append([k,img_path])\n",
    "\n",
    "clothing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e48dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['short sleeve top',\n",
       " 'long sleeve top',\n",
       " 'short sleeve outwear',\n",
       " 'long sleeve outwear',\n",
       " 'vest',\n",
       " 'sling',\n",
       " 'shorts',\n",
       " 'trousers',\n",
       " 'skirt',\n",
       " 'short sleeve dress',\n",
       " 'long sleeve dress',\n",
       " 'vest dress',\n",
       " 'sling dress']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = [\"short sleeve top\",\"long sleeve top\",\"short sleeve outwear\",\"long sleeve outwear\",\"vest\",\"sling\",\"shorts\",\"trousers\",\"skirt\", \"short sleeve dress\", \"long sleeve dress\", \"vest dress\",\"sling dress\"]\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd465853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clothing, val_clothing = train_test_split(clothing, test_size=0.1)\n",
    "len(train_clothing), len(val_clothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df440d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082d40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(clothing, categories, dataset_type):\n",
    "\n",
    "    images_path = Path(f\"dress/images/{dataset_type}\")\n",
    "    labels_path = Path(f\"dress/labels/{dataset_type}\")\n",
    "    \n",
    "    for img_id, rtest in enumerate(tqdm(clothing)):\n",
    "        image_name = f\"{img_id}.jpeg\"\n",
    "#         img = cv2.imread(rtest[1])\n",
    "        img = Image.open(rtest[1])\n",
    "        img = img.convert('RGB')\n",
    "        img.save(str(images_path / image_name), \"JPEG\")\n",
    "        \n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        label_name = f\"{img_id}.txt\"\n",
    "        with (labels_path / label_name).open(mode=\"w\") as label_file:\n",
    "            l = len(rtest[0])-2 # removing source and pair id for item count \n",
    "            # rtest[0][\"item1\"]\n",
    "            for i in range(1,l+1):\n",
    "                pts = rtest[0][f\"item{i}\"][\"bounding_box\"]\n",
    "                top_l = pts[:2]\n",
    "                lower_r = pts[2:]\n",
    "                \n",
    "                top_l_n = [pts[0]/img_width, pts[1]/img_height]\n",
    "                lower_r_n = [pts[2]/img_width, pts[3]/img_height]\n",
    "                \n",
    "                w = lower_r_n[0]-top_l_n[0]\n",
    "                h = lower_r_n[1]-top_l_n[1]\n",
    "#                 tl = [top_l[0]/]\n",
    "#                 print(\"pts     :\",pts)\n",
    "#                 print(\"top_l   :\",top_l)\n",
    "#                 print(\"lower_r :\",lower_r)\n",
    "                label = rtest[0][f\"item{i}\"][\"category_name\"]\n",
    "                category_idx = categories.index(label)\n",
    "                label_file.write(\n",
    "                f\"{category_idx} {top_l_n[0] + w / 2} {top_l_n[1] + h / 2} {w} {h}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d5aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:05<00:00, 33.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 29.06it/s]\n"
     ]
    }
   ],
   "source": [
    "create_dataset(train_clothing, cat, 'train')\n",
    "create_dataset(val_clothing, cat, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17f4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdress\u001b[00m\r\n",
      "â”œâ”€â”€ \u001b[01;34mimages\u001b[00m\r\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;34mtrain\u001b[00m\r\n",
      "â”‚Â Â  â””â”€â”€ \u001b[01;34mval\u001b[00m\r\n",
      "â””â”€â”€ \u001b[01;34mlabels\u001b[00m\r\n",
      "    â”œâ”€â”€ \u001b[01;34mtrain\u001b[00m\r\n",
      "    â””â”€â”€ \u001b[01;34mval\u001b[00m\r\n",
      "\r\n",
      "6 directories, 0 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree dress -L 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0285f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rohitreddypanyam/myntra/dev/yolov5\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe59e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3809d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=models/yolov5x.yaml, data=data/dress.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=yolov5x_clothing, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 1 commit. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 ðŸš€ v6.0-52-g8a803f3 torch 1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1    121122  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
      "Model Summary: 567 layers, 86298562 parameters, 86298562 gradients\n",
      "\n",
      "Transferred 738/745 items from yolov5x.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 123 weight, 126 weight (no decay), 126 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../dress/labels/train' images and labels...180 found, 0 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../dress/labels/train.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 248.31it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../dress/labels/val' images and labels...20 found, 0 missing, 0 e\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../dress/labels/val.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 129.50it/s]\u001b[0m\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.53, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov5x_clothing3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/29        0G   0.07417   0.03325   0.04607        12       640:   0%| | ^C\n",
      "      0/29        0G   0.07417   0.03325   0.04607        12       640:   0%| | \n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 625, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 522, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 344, in train\n",
      "    callbacks.run('on_train_batch_end', ni, model, imgs, targets, paths, plots, opt.sync_bn)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/utils/callbacks.py\", line 76, in run\n",
      "    logger['callback'](*args, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/utils/loggers/__init__.py\", line 86, in on_train_batch_end\n",
      "    self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/jit/_trace.py\", line 733, in trace\n",
      "    return trace_module(\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/jit/_trace.py\", line 934, in trace_module\n",
      "    module._c._create_method_from_trace(\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/models/yolo.py\", line 127, in forward\n",
      "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/models/yolo.py\", line 150, in _forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/models/common.py\", line 137, in forward\n",
      "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/models/common.py\", line 103, in forward\n",
      "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/myntra/dev/yolov5/models/common.py\", line 45, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 887, in _call_impl\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 860, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 399, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/Users/rohitreddypanyam/opt/anaconda3/envs/CV/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 395, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# !!!!!!!! normalize the values.\n",
    "!python train.py --img 640 --batch 4 --epochs 30 \\\n",
    "  --data data/dress.yaml --cfg models/yolov5x.yaml --weights yolov5x.pt \\\n",
    "  --name yolov5x_dress --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5282b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa797a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../dress/images/val/ -maxdepth 1 -type f | head -50 | xargs cp -t \"./inference/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f232d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecting usig model\n",
    "\n",
    "!python detect.py --weights weights/best_yolov5x_dress.pt \\\n",
    "  --img 640 --conf 0.4 --source ./inference/images/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
